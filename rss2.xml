<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Yunsaijc&#39;s Blog</title>
    <link>http://yunsaijc.top/</link>
    
    <atom:link href="http://yunsaijc.top/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Enjoy</description>
    <pubDate>Sun, 08 Oct 2023 13:46:36 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>&lt;A Survey of Large Language Models&gt;阅读笔记</title>
      <link>http://yunsaijc.top/2023/10/08/11-%3CA%20Survey%20of%20Large%20Language%20Models%3E%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <guid>http://yunsaijc.top/2023/10/08/11-%3CA%20Survey%20of%20Large%20Language%20Models%3E%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <pubDate>Sun, 08 Oct 2023 11:47:08 GMT</pubDate>
      
        
        
      <description>&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a
href=&quot;https://arxiv.org/abs/2303.18223&quot;&gt;https://arxiv.org/abs/2303.18223&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;</description>
        
      
      
      
      <content:encoded><![CDATA[<blockquote><p>原文链接：<ahref="https://arxiv.org/abs/2303.18223">https://arxiv.org/abs/2303.18223</a></p></blockquote><h2 id="intro">Intro</h2><p>为了让机器像人类一样阅读、写作和交流，语言建模(LM)是提高机器语言智能的主要方法之一。其原理是对词语序列的生成概率进行建模，以预测未来的、或缺失的单词的概率。</p><p>LM的发展可以分为4个阶段： -统计语言模型SLM：基于统计学习方法开发。基本思想是基于马尔可夫假设来建立词频预测模型- 神经语言模型NLM：通过神经网络（如RNN）来描述单词序列的概率 -预训练语言模型PLM：确立了“预训练和微调”的学习范式 -大语言模型LLM：通过对PLM的模型或数据大小进行扩展，能够提高下游任务的模型性能。与较小的PLM相比，LLM展现出了“涌现能力”</p><h2 id="背景">背景</h2><p>通常，LLM指包含千亿（100B）或更多参数的Transformer语言模型。现有的LLM 采用类似的 Transformer 架构和与小型语言模型相同的预训练目标(如语言建模)</p><h3 id="llm的扩展法则">LLM的扩展法则</h3><p>KM扩展法则：是由Kaplan等人提出的，神经语言模型的性能与模型规模<spanclass="math inline">\((N)\)</span>、数据集规模<spanclass="math inline">\((D)\)</span>和训练计算量<spanclass="math inline">\((C)\)</span>之间的幂律关系: <spanclass="math display">\[\begin{aligned}&amp;L(N)=(\frac{N_c}{N})^{\alpha_N},\ \alpha_N\sim0.076,\ N_c\sim8.8\times10^{13}\\&amp;L(D)=(\frac{D_c}{D})^{\alpha_D},\ \alpha_D\sim0.095,\ D_c\sim5.4\times10^{13}\\&amp;L(C)=(\frac{C_c}{C})^{\alpha_C},\ \alpha_C\sim0.050,\ C_c\sim3.1\times10^{8}\end{aligned}\]</span> 其中，<spanclass="math inline">\(L(\cdot)\)</span>为用nats表示的交叉熵损失，<spanclass="math inline">\(c\)</span>为给定的计算预算。</p><h3 id="llm的涌现能力">LLM的涌现能力</h3><p>定义：在小型模型中不存在但在大型模型中产生的能力（是区别 LLM 与先前PLM 的最显著特征之一）</p><p>LLM的三种典型涌现能力： - 上下文学习(ICL)：ICL 能力是由 GPT-3正式引入的。假设已经为LLM提供了一个自然语言指令和/或几个任务演示，它可以通过完成输入文本的单词序列的方式来为测试实例生成预期的输出，而无需额外的训练或梯度更新（如：175B的GPT-3 模型在一般情况下表现出强大的 ICL 能力） -指令遵循：通过使用自然语言描述的混合多任务数据集进行微调（称为指令微调），LLM在未见过的以指令形式描述的任务上表现出色，具有更好的泛化能力 -逐步推理：对于小型语言模型而言，通常很难解决涉及多个推理步骤的复杂任务，例如数学问题。然而，通过使用思维链(Chain-of-Thought,CoT)提示策略，LLM可以通过利用包含中间推理步骤的提示机制来解决这类任务，从而得出最终答案。</p><h3 id="llm的关键技术">LLM的关键技术</h3><p>LLM目前的角色就像一个通用、且有能力的学习者。导致其成功的关键技术包括：- <strong>扩展</strong>：如前面所说，Transformer语言模型存在明显的扩展效应:更大的模型/数据规模和更多的训练计算通常会导致模型能力的提升-<strong>训练</strong>：大规模使分布式训练成为必须；此外，优化技巧对于训练的稳定性和模型性能也非常重要- <strong>能力引导</strong>：LLM具备了解决通用任务的潜在能力，而当执行一些特定任务时，这些能力可能不会展示出来。设计合适的任务指令或具体的ICL 策略可以激发这些能力 - <strong>对齐微调</strong>：LLM的预训练数据中包含低质量的数据，它可能会生成有毒、偏见甚至有害的内容。因此，有必要使LLM 与人类价值观保持一致。InstructGPT 使 LLM能够按照期望的指令进行操作，它利用了基于人类反馈的强化学习技术，将人类纳入训练循环中；ChatGPT采用类似于 InstructGPT的技术，在产生高质量、无害的回答方面表现出很强的对齐能力。 -<strong>工具操作</strong>：LLM基于海量纯文本语料库进行训练，因此在那些非文本的任务上表现不佳（如数字计算）。此外，它们的能力也受限于预训练数据（如无法获取最新信息）。为了解决这些问题，学者们提出利用外部工具来弥补LLM 的不足（如，利用计算器进行准确计算、利用搜索引擎检索未知信息）。ChatGPT 已经实现了使用外部插件的机制，这种机制可以广泛扩展 LLM的能力范围。</p><h3 id="gpt系列模型的技术演进">GPT系列模型的技术演进</h3><p>ChatGPT 基于功能强大的 GPT模型开发，其对话能力得到了专门的优化，在社会上引起了广泛关注。</p><ul><li>2018～GPT-1：GPT 代表生成式预训练(GenerativePre-Training)。它是基于生成型的、仅解码器的 Transformer架构开发的，并采用了无监督预训练和有监督微调的混合方法。它为 GPT系列模型建立了核心架构，并确立了对自然语言文本进行建模的基本原则，即预测下一个单词</li><li>2019～GPT-2：采用了与 GPT-1 类似的架构，将参数规模增加到了 15亿，并使用大规模的网页数据集 WebText进行训练。它旨在通过无监督语言建模来执行任务，而无需使用标记数据进行显式微调。论文中提出，自然语言文本可以自然地用作为格式化输入、输出和任务信息的统一方式，<strong>解决任务的过程可以被视为生成解决方案文本的单词预测问题</strong>。也就是说，每个NLP任务可以被视为基于世界文本的子集的单词预测问题，因此如果模型训练后具有足够能力以复原世界文本，无监督语言建模可以解决各种任务</li><li>2020～GPT-3：它扩展了（几乎相同的）生成式预训练架构，将模型参数扩展到了175B。论文中正式介绍了ICL，它是以小样本或零样本的方式使用LLM，可以指导 LLM 理解以自然语言文本的形式给出的任务。GPT-3 可以被视为从PLM 到 LLM进化过程中的一个重要里程碑。它通过实证证明，将神经网络扩展到大的规模可以大幅增加模型的能力</li></ul><p>此后，OpenAI从两个方面对GPT-3进行改进： 1.使用代码进行训练，以解决GPT难以推理复杂任务（如代码、数学）的能力；2.</p>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</category>
      
      
      <category domain="http://yunsaijc.top/tags/AI/">AI</category>
      
      <category domain="http://yunsaijc.top/tags/LLM/">LLM</category>
      
      
      <comments>http://yunsaijc.top/2023/10/08/11-%3CA%20Survey%20of%20Large%20Language%20Models%3E%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>AI方向直博学习日志</title>
      <link>http://yunsaijc.top/2023/10/07/10-%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</link>
      <guid>http://yunsaijc.top/2023/10/07/10-%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</guid>
      <pubDate>Sat, 07 Oct 2023 12:34:16 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;年&quot;&gt;2023年&lt;/h2&gt;
&lt;h3 id=&quot;月&quot;&gt;10月&lt;/h3&gt;
&lt;h4 id=&quot;日&quot;&gt;8日&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;文献阅读：&amp;lt;A Survey of Large Language Models&amp;gt;&lt;/li&gt;
&lt;li&gt;LLM建立的主要基础-Tra</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="年">2023年</h2><h3 id="月">10月</h3><h4 id="日">8日</h4><ul><li>文献阅读：&lt;A Survey of Large Language Models&gt;</li><li>LLM建立的主要基础-Transformer架构：<ahref="https://zhuanlan.zhihu.com/p/338817680">https://zhuanlan.zhihu.com/p/338817680</a></li><li>循环神经网络(RNN)：个人理解-就像在CNN中采用了密码学的 <spanclass="math inline">\(CBC/CFB/OFB\)</span>工作模式一样，将上一轮结果反馈到下一轮，用于更好地处理前后文相关的序列信息（<ahref="https://zhuanlan.zhihu.com/p/30844905">https://zhuanlan.zhihu.com/p/30844905</a>）</li><li>机器学习中的正则化(Regulation)：<ahref="https://www.zhihu.com/question/20924039">https://www.zhihu.com/question/20924039</a></li><li>LLM微调学习：Hugging face Transformer文档初步阅读</li><li>实验环境初步搭建</li></ul><h4 id="日-1">7日</h4><ul><li>初步确定短期研究方向</li><li>监督学习：关键在于，数据中有无人工标注的标签（<ahref="https://zhuanlan.zhihu.com/p/376931561">https://zhuanlan.zhihu.com/p/376931561</a>）</li><li>泛化(Generalization)：是指模型很好地拟合以前未见过的新数据（从用于创建该模型的同一分布中抽取）的能力（<ahref="https://www.cnblogs.com/anliven/p/10264475.html">https://www.cnblogs.com/anliven/p/10264475.html</a>）</li><li>注意力机制：通过权重，将模型的注意力转移到重要的部位（<ahref="https://zhuanlan.zhihu.com/p/379722366">https://zhuanlan.zhihu.com/p/379722366</a>）</li><li>欧氏空间的通俗理解：<ahref="https://www.zhihu.com/question/27903807">https://www.zhihu.com/question/27903807</a></li><li>图神经网络(GNN)基本原理：<ahref="https://blog.csdn.net/weixin_45884316/article/details/115751272">https://blog.csdn.net/weixin_45884316/article/details/115751272</a></li></ul>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/AI%E5%9F%BA%E7%A1%80/">AI基础</category>
      
      
      <category domain="http://yunsaijc.top/tags/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/">学习日志</category>
      
      
      <comments>http://yunsaijc.top/2023/10/07/10-%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>将博客搬至CSDN</title>
      <link>http://yunsaijc.top/2023/10/07/11-%E5%B0%86%E5%8D%9A%E5%AE%A2%E6%90%AC%E8%87%B3CSDN/</link>
      <guid>http://yunsaijc.top/2023/10/07/11-%E5%B0%86%E5%8D%9A%E5%AE%A2%E6%90%AC%E8%87%B3CSDN/</guid>
      <pubDate>Sat, 07 Oct 2023 12:34:16 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;年&quot;&gt;2023年&lt;/h2&gt;
</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="年">2023年</h2>]]></content:encoded>
      
      
      
      
      <comments>http://yunsaijc.top/2023/10/07/11-%E5%B0%86%E5%8D%9A%E5%AE%A2%E6%90%AC%E8%87%B3CSDN/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>AI中的线性代数（有空更新）</title>
      <link>http://yunsaijc.top/2023/10/05/9-AI%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</link>
      <guid>http://yunsaijc.top/2023/10/05/9-AI%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</guid>
      <pubDate>Thu, 05 Oct 2023 09:08:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;基本符号&quot;&gt;基本符号&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&quot;math inline&quot;&gt;\(A \in \mathbb{R}^{m\times
n}\)&lt;/span&gt;表示一个&lt;span class=&quot;math inline&quot;&gt;\(m\)&lt;/span&gt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="基本符号">基本符号</h2><ul><li><span class="math inline">\(A \in \mathbb{R}^{m\timesn}\)</span>表示一个<span class="math inline">\(m\)</span>行<spanclass="math inline">\(n\)</span>列的实数矩阵(matrix)</li><li><span class="math inline">\(x\in\mathbb{R}^n\)</span>表示一个有<spanclass="math inline">\(n\)</span>个元素的向量(vector)。通常来说，一个<spanclass="math inline">\(n\)</span>维向量指的是一个<spanclass="math inline">\(n\times 1\)</span>的矩阵（即列向量(columnvector)）。通过转置(transpose)可以表示对应的<spanclass="math inline">\(1\times n\)</span>矩阵（即行向量(rowvector)）</li><li><span class="math inline">\(x_i\)</span>表示向量<spanclass="math inline">\(x\)</span>的第<spanclass="math inline">\(i\)</span>个元素</li><li><span class="math inline">\(a_{ij}\ or\ A_{ij}\)</span>表示矩阵<spanclass="math inline">\(A\)</span>中<spanclass="math inline">\(i\)</span>行<spanclass="math inline">\(j\)</span>列的元素</li><li><span class="math inline">\(a_j\ or\ A_{:,j}\)</span>表示矩阵<spanclass="math inline">\(A\)</span>的第<spanclass="math inline">\(j\)</span>列</li><li><span class="math inline">\(a_i^T\ or\ A_{i,:}\)</span>表示矩阵<spanclass="math inline">\(A\)</span>的第<spanclass="math inline">\(i\)</span>行</li></ul><h2 id="矩阵乘法matrix-multiplication">矩阵乘法(MatrixMultiplication)</h2><ul><li>矩阵<span class="math inline">\(A \in \mathbb{R}^{m\timesn}\)</span>和矩阵<span class="math inline">\(B \in \mathbb{R}^{n\timesp}\)</span>的乘积(product)是<span class="math inline">\(C=AB\in\mathbb{R}^{m\times p}\)</span>，其中<spanclass="math inline">\(C_{ij}=\sum^n_{k=1}A_{ik}B_{kj}\)</span></li><li>性质<ul><li>结合律(associative)：<spanclass="math inline">\((AB)C=A(BC)\)</span></li><li>分配律(distributive)：<spanclass="math inline">\(A(B+C)=AB+AC\)</span></li><li>不可交换(not commutative)：<span class="math inline">\(AB\neqBA\)</span></li></ul></li></ul><h2 id="操作与性质">操作与性质</h2><h3id="单位矩阵identity-matrix与对角矩阵diagonal-matrix">单位矩阵(IdentityMatrix)与对角矩阵(Diagonal Matrix)</h3><ul><li>单位阵<span class="math display">\[  I_{ij}=\left\{\begin{matrix}   1,\ i=j\\0,\ i\neq j \end{matrix}\right.  \]</span></li><li>满足对任意<span class="math inline">\(A\in \mathbb{R}^{m\timesn}\)</span>都有<span class="math inline">\(AI=A=IA\)</span></li><li>对角阵，通常记为<spanclass="math inline">\(D=diag(d_1,d_2,...,d_n)\)</span>，有<spanclass="math display">\[ D_{ij}=\left\{\begin{matrix}   D_i,\ i=j\\0,\ i\neq j \end{matrix}\right.  \]</span></li></ul><h3 id="转置transpose">转置(Transpose)</h3><ul><li><span class="math inline">\((A^T)_{ij}=A_{ji}\)</span></li><li>性质<ul><li><span class="math inline">\((A^T)^T=A\)</span></li><li><span class="math inline">\((AB)^T=B^TA^T\)</span></li><li><span class="math inline">\((A+B)^T=A^T+B^T\)</span></li></ul></li></ul><h3 id="对称矩阵symmetric-matrix">对称矩阵(Symmetric Matrix)</h3><ul><li>当<span class="math inline">\(A\in \mathbb{R}^{n\timesn}\)</span>且<span class="math inline">\(A^T=A\)</span>，则<spanclass="math inline">\(A\)</span>为对称阵；若<spanclass="math inline">\(A=-A^T\)</span>则<spanclass="math inline">\(A\)</span>为反对称阵(anti-symmetric)</li><li>对于任意<span class="math inline">\(A\in \mathbb{R}^{n\timesn}\)</span>，<span class="math inline">\(A+A^T\)</span>是对称阵，<spanclass="math inline">\(A-A^T\)</span>是反对称阵</li><li>因此任意方阵都可以表示为一个对称阵和一个反对称阵的和：<spanclass="math inline">\(A=\frac{1}{2}(A+A^T)+\frac{1}{2}(A-A^T)\)</span></li><li>对称阵在实践中非常常见，通常将所有大小为<spanclass="math inline">\(n\)</span>（即<span class="math inline">\(n\timesn\)</span>）的对称阵的集合记为<spanclass="math inline">\(\mathbb{S}^n\)</span></li></ul><h3 id="迹trace">迹(Trace)</h3><h2 id="参考">参考</h2><blockquote><p><ahref="https://www.yanxishe.com/TextTranslation/2965">https://www.yanxishe.com/TextTranslation/2965</a></p><p><ahref="https://cs229.stanford.edu/section/cs229-linalg.pdf">https://cs229.stanford.edu/section/cs229-linalg.pdf</a></p></blockquote>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/AI%E5%9F%BA%E7%A1%80/">AI基础</category>
      
      
      <category domain="http://yunsaijc.top/tags/AI/">AI</category>
      
      <category domain="http://yunsaijc.top/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</category>
      
      
      <comments>http://yunsaijc.top/2023/10/05/9-AI%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>信息安全数学基础总结（有空更新）</title>
      <link>http://yunsaijc.top/2023/10/03/8-%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/</link>
      <guid>http://yunsaijc.top/2023/10/03/8-%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/</guid>
      <pubDate>Tue, 03 Oct 2023 05:48:59 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;大二第一学期，学院开设了《信息安全数学基础》这门课。但由于当时对信息安全的理解还不够深入，再加上已经过去了两年之久，很多知识都理解得不好，且印象模糊。借着大四这个相对空闲的时间，对学过的知识进行复习和总结。&lt;/p&gt;
&lt;h2 id=&quot;初等数论&quot;&gt;初等数论&lt;/h2&gt;
&lt;h3 i</description>
        
      
      
      
      <content:encoded><![CDATA[<p>大二第一学期，学院开设了《信息安全数学基础》这门课。但由于当时对信息安全的理解还不够深入，再加上已经过去了两年之久，很多知识都理解得不好，且印象模糊。借着大四这个相对空闲的时间，对学过的知识进行复习和总结。</p><h2 id="初等数论">初等数论</h2><h3 id="整数的因子分解">整数的因子分解</h3><h4 id="整除">整除</h4><ul><li><span class="math inline">\(a,\ b\in \mathbb{Z},\ b\neq 0,\quad 若\\exists\ q,\ 使得\  a=qb,\ 则\ b\mid a\ (b整除a),\ 否则\ b\nmida\)</span></li><li><span class="math inline">\(b\)</span>称为<spanclass="math inline">\(a\)</span>的因子，<spanclass="math inline">\(a\)</span>称为<spanclass="math inline">\(b\)</span>的倍数</li><li>性质<ul><li>传递性：<span class="math inline">\(c\mid b,\ b\mid a,\ then\ c\mida\)</span></li><li><span class="math inline">\(b\mid a,\ then\ bc\mid ac\)</span></li><li><span class="math inline">\(c\mid a,\ c\mid b,\ then\ c\midma+nb\)</span></li></ul></li></ul><h4 id="euclid欧几里得除法">Euclid(欧几里得)除法</h4><ul><li><span class="math inline">\(a,\ b\in \mathbb{Z},\ b&gt;0,\则存在唯一的整数对q,r\ 使得\ a=qb+r,\ 0\leq r&lt;b\)</span></li><li><span class="math inline">\(q\)</span>称为不完全商，<spanclass="math inline">\(r\)</span>称为余数（最小非负余数）</li><li>若调整<span class="math inline">\(q\)</span>（一般是加1）使得<spanclass="math inline">\(|r|\leq \frac{b}{2}\)</span>，则<spanclass="math inline">\(r\)</span>为绝对值最小余数（在Euclid算法中起到加速的作用）</li><li>可用于求整数的<span class="math inline">\(a\)</span>进制表示<img src="/2023/10/03/8-%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/1.png" class=""></li></ul><h4 id="公因子与最大公因子">公因子与最大公因子</h4><ul><li>设<span class="math inline">\(a,a_2,…,a_n\)</span>是<spanclass="math inline">\(n(n\geq2)\)</span>个整数，若整数<spanclass="math inline">\(d\)</span>是它们中每一个数的因数，则<spanclass="math inline">\(d\)</span>称<spanclass="math inline">\(a,a_2,…,a_n\)</span>的一个公因子</li><li>若<span class="math inline">\(a,a_2,…,a_n\)</span>不全为零，则<spanclass="math inline">\(a,a_2,…,a_n\)</span>的所有公因子中最大的一个称为最大公因子，记为<spanclass="math inline">\((a,a_2,…,a_n)\)</span></li><li>特别地，当<spanclass="math inline">\((a,a_2,…,a_n)=1\)</span>，称<spanclass="math inline">\(a,a_2,…,a_n\)</span>互素/互质</li><li>定义<spanclass="math inline">\((0,a)=a\)</span>，因为任何非零整数都是<spanclass="math inline">\(0\)</span>的因数</li></ul><p>辗转相除法/Euclid算法 求最大公因子</p><ul><li><p>预备定理：<span class="math inline">\(a,b,r是不全为0的整数,\若a=qb+r,\ q\in\mathbb{Z},\ 则(a,b)=(b,r)\)</span><img src="/2023/10/03/8-%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/2.png" class=""></p></li><li><p>将上述辗转相除的过程反过来写（即把余数放左边，用<spanclass="math inline">\(a,b\)</span>来表示余数），可以得到最大公因子的线性表示，即贝祖等式</p></li><li><p>贝祖等式：对任意两个正整数<spanclass="math inline">\(a,b\)</span>，存在整数<spanclass="math inline">\(x,y使得(a,b)=xa+yb\)</span></p></li><li><p>当<spanclass="math inline">\((a,b)=1\)</span>，可以求出唯一解<spanclass="math inline">\(x\)</span>，即<span class="math inline">\(xa\equiv1(mod\ b),\ x\equiv a^{-1}(mod\ b)\)</span></p></li><li><p>扩展/广义Euclid算法：求出最大公因子的同时求出系数<spanclass="math inline">\(x,y\)</span>（主要用于求乘法逆元）</p></li><li><p>伪代码 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Input: 非负整数a, b且a&gt;=b (先将待计算的整数取绝对值)</span><br><span class="line">Output: r=(a,b) 以及满足 sa+tb=(a,b)的s,t</span><br><span class="line">Extended Euclid(a,b)&#123;</span><br><span class="line">(r,s,t) &lt;- (a,1,0);</span><br><span class="line">(r&#x27;,s&#x27;,t&#x27;) &lt;- (b,0,1);</span><br><span class="line">While r&#x27;!=0 do&#123;</span><br><span class="line">q &lt;- floor(r/r&#x27;);</span><br><span class="line">(tmp1,tmp2,tmp3) &lt;- (r-qr&#x27;,s-qs&#x27;,t-qt&#x27;);</span><br><span class="line">(r,s,t) &lt;- (r&#x27;,s&#x27;,t&#x27;);</span><br><span class="line">(r&#x27;,s&#x27;,t&#x27;) &lt;- (tmp1,tmp2,tmp3);</span><br><span class="line">&#125;</span><br><span class="line">Return r,s,t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li><li><p>最大公因子等价定义：<spanclass="math inline">\(a,b\)</span>是不全为零的整数，则<spanclass="math inline">\(d=(a,b)\)</span>是集合<spanclass="math inline">\(\{xa+yb|x,y\in\mathbb{Z}\}\)</span>中的最小正整数</p></li><li><p>应用-方程有解的判定：<spanclass="math inline">\(a,b\)</span>是不全为零的整数，则方程<spanclass="math inline">\(ax+by=c有整数解\Leftrightarrow (a,b)\midc\)</span> &gt;个人理解：对于整数<spanclass="math inline">\(a,b\)</span>，他们的最大公因子就是使用这两个数能得到的最小度量&gt; &gt;换句话说，即长度为<spanclass="math inline">\(a,b\)</span>的两把尺子可以度量的最小长度</p></li></ul><h4 id="素数">素数</h4><ul><li>埃拉托色尼素数筛选法-快速计算<spanclass="math inline">\(1\)</span>到<spanclass="math inline">\(N\)</span>之间的所有素数：遍历<spanclass="math inline">\(1\)</span>到<spanclass="math inline">\(\sqrt{N}\)</span>，将其中所有素数的倍数去掉，剩下的便都是素数了</li><li>素性定理：<span class="math inline">\(p\)</span>为素数，<spanclass="math inline">\(a,b\)</span>为整数，若<spanclass="math inline">\(p\mid ab\)</span>，则<spanclass="math inline">\(p\mid a\)</span>或<spanclass="math inline">\(p\mid b\)</span> ^291cce</li><li>算数基本定理：任意整数<span class="math inline">\(n\(n&gt;1)\)</span>都可以分解为有限个素数的乘积<spanclass="math inline">\(n=p_1p_2...p_s\)</span>，该分解除了素数因子的排列之外，是唯一的</li><li>唯一因子分解定理：任意整数<span class="math inline">\(n\(n&gt;1)\)</span>可以唯一地表示成<spanclass="math inline">\(n=p_1^{\alpha_1}p_2^{\alpha_2}...p_s^{\alpha_s},\\alpha_i &gt;0\)</span>，其中<spanclass="math inline">\(p_1p_2...p_s\)</span>为素数<spanclass="math inline">\(p_i&lt;p_j\ (i&lt;j)\)</span>。上式叫做<spanclass="math inline">\(n\)</span>的标准分解式。</li></ul><p>整数的一些性质</p><ul><li><spanclass="math inline">\(a=p_1^{\alpha_1}p_2^{\alpha_2}...p_s^{\alpha_s},\b=p_1^{\beta_1}p_2^{\beta_2}...p_s^{\beta_s}\)</span>，那么<spanclass="math inline">\((a,b)=p_1^{\gamma_1}p_2^{\gamma_2}...p_s^{\gamma_s},\\gamma_i=min(\alpha_i,\beta_i)\)</span>，最小公倍数<spanclass="math inline">\([a,b]=p_1^{\delta_1}p_2^{\delta_2}...p_s^{\delta_s},\\delta_i=max(\alpha_i,\beta_i)\)</span></li><li><span class="math inline">\(a_1,a_2,...a_n\)</span>为<spanclass="math inline">\(n\)</span>个非零整数，令<spanclass="math inline">\([a_1,a_2]=m_1,\[m_1,a_3]=m_2,...,[m_{n-2},a_n]=m_{n-1}\)</span>，则<spanclass="math inline">\([a_1,a_2,...a_n]=m_{n-1}\)</span></li><li>除了2以外，所有素数都是奇素数</li></ul><h4 id="多项式的整除性">多项式的整除性</h4><ul><li>令<span class="math inline">\(\mathbb{Q}=\{\frac{a}{b}|a,b\in\mathbb{Z},b\neq0\}\)</span>表示全体有理数的集合。<spanclass="math inline">\(\mathbb{Q}\)</span>上有加减乘除四则运算</li><li>令<spanclass="math inline">\(\mathbb{Q}[x]=\{a_0+a_1x+...+a_nx^n|a_i\in\mathbb{Q},0\leqi\leq n\}\)</span>表示所有系数为有理数的多项式集合。<spanclass="math inline">\(\mathbb{Q}[x]\)</span>有加减乘，但没有除法</li><li>可以发现<spanclass="math inline">\(\mathbb{Q}[x]\)</span>与整数集合<spanclass="math inline">\(\mathbb{Z}\)</span>有很多类似的性质：都有带余除法、最大公因子、唯一因子分解定理等</li></ul><p>（多项式<span class="math inline">\(f(x)\)</span>的次数表示为<spanclass="math inline">\(deg\ f(x)\)</span>，以下多项式均在<spanclass="math inline">\(\mathbb{Q}[x]\)</span>内讨论）</p><ul><li><span class="math inline">\(g(x)\neq 0\)</span>，则有<spanclass="math inline">\(q(x),r(x)\)</span>使得<spanclass="math inline">\(f(x)=q(x)g(x)+r(x),\ r(x)=0或r(x)\neq 0,deg\ r(x)&lt; deg\ g(x)\)</span></li><li><span class="math inline">\(r(x)=0\)</span>时，称<spanclass="math inline">\(g(x)整除f(x)\)</span>，记<spanclass="math inline">\(g(x)|f(x)\)</span>，<spanclass="math inline">\(g(x)\)</span>称为<spanclass="math inline">\(f(x)\)</span>的因子</li><li>当<span class="math inline">\(g(x)\)</span>为<spanclass="math inline">\(f(x)\)</span>的因子，且<spanclass="math inline">\(deg\ g(x) &lt; deg\ f(x)\)</span>时，<spanclass="math inline">\(g(x)\)</span>称为<spanclass="math inline">\(f(x)\)</span>的真因子</li><li>当<spanclass="math inline">\(f(x)\)</span>没有真因子时，称为不可约多项式</li></ul><blockquote><p>个人理解：把函数的符号<spanclass="math inline">\(f,g\)</span>当成整数的符号来看，多项式的整除与整数的整除几乎相同，只是多了<spanclass="math inline">\(x\)</span>而已</p><p>因此其余的不再赘述：</p><p>多项式整除性质——参考整数整除性质</p><p>多项式最大公因子——参考整数最大公因子</p><p>多项式最大公因子的表示——参考整数最大公因子的表示（贝祖等式）</p><p>多项式最大公因子的求法——参考整数的辗转相除法</p><p>不可约多项式的有关定理——参考整数的素性定理</p><p>多项式的唯一分解定理——参考整数的唯一分解定理</p></blockquote><h3 id="同余式">同余式</h3><h3 id="二次剩余">二次剩余</h3><h2 id="抽象代数">抽象代数</h2><h3 id="群">群</h3><h3 id="环">环</h3><h3 id="域">域</h3><h3 id="有限域">有限域</h3><h2 id="参考">参考</h2>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/">网络空间安全基础</category>
      
      
      <category domain="http://yunsaijc.top/tags/%E6%95%B0%E5%AD%A6/">数学</category>
      
      <category domain="http://yunsaijc.top/tags/%E6%95%B0%E8%AE%BA/">数论</category>
      
      <category domain="http://yunsaijc.top/tags/%E6%8A%BD%E8%B1%A1%E4%BB%A3%E6%95%B0/">抽象代数</category>
      
      
      <comments>http://yunsaijc.top/2023/10/03/8-%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>关于HTTP反向代理的理解</title>
      <link>http://yunsaijc.top/2023/09/27/7-%E5%85%B3%E4%BA%8EHTTP%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <guid>http://yunsaijc.top/2023/09/27/7-%E5%85%B3%E4%BA%8EHTTP%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <pubDate>Wed, 27 Sep 2023 05:48:59 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;正向代理forward-proxy&quot;&gt;正向代理(Forward Proxy)&lt;/h2&gt;
&lt;p&gt;正向代理通常直接称为代理(&lt;code&gt;Proxy&lt;/code&gt;)，也就是日常情景下使用的各种&lt;code&gt;BrupSuite、梯子&lt;/code&gt;等的代理，需要我们手动进行配</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="正向代理forward-proxy">正向代理(Forward Proxy)</h2><p>正向代理通常直接称为代理(<code>Proxy</code>)，也就是日常情景下使用的各种<code>BrupSuite、梯子</code>等的代理，需要我们手动进行配置。</p><h3 id="代理的作用">代理的作用</h3><ul><li>便于安全审计：所有流量经过一台代理服务器，那么安全审计就容易得多</li><li>加速访问/节省带宽：代理服务器可以返回缓存好的内容，无需向外网发出请求，从而加快访问速度、节省带宽</li><li>保护个人信息：使用代理隐藏自己的真实IP地址</li><li>突破访问限制：有时自己的地址被禁止访问，可以连接白名单上的代理服务器来进行访问</li></ul><h2 id="反向代理reverse-proxy">反向代理((Reverse Proxy)</h2><p>个人理解：类似于计算机网络中的NAT(网络地址转发)技术。用户并不知道自己被“反向代理”了，反向代理服务器(如<code>Nginx</code>)接收到请求后，转发给Web服务器(如<code>Apache</code>)进行处理。</p><p>为了方便阅读，此处开始用<code>Nginx</code>来指代<code>反向代理服务器</code>。</p><h3 id="反向代理作用">反向代理作用</h3><ul><li>负载均衡：访问压力大时，<code>Nginx</code>可以将请求分配给多个不同的Web服务器进行处理，而用户访问的地址仍然是相同的地址(即<code>Nginx</code>服务器的地址)</li><li>提高安全性：Web服务器对外不可见，此时<code>Nginx</code>相当于一个防火墙</li><li>节省IP资源：如上述对反向代理的个人理解所说，类似于NAT，能够节省IP资源</li><li>加速访问：<code>Nginx</code>同样可以缓存网页内容</li></ul><h2 id="总结">总结</h2><p>可以理解为：</p><ul><li>正向代理是面向用户的代理</li><li>反向代理是面向服务器的代理，对用户透明（也就是说把服务器也当成用户，服务器在给用户返回请求时自己挂了一个代理）</li></ul><h2 id="参考">参考</h2><blockquote><p><ahref="https://zhuanlan.zhihu.com/p/464965616">https://zhuanlan.zhihu.com/p/464965616</a></p><p><ahref="https://www.zhihu.com/question/388303662">https://www.zhihu.com/question/388303662</a></p><p><ahref="https://zhuanlan.zhihu.com/p/486180243">https://zhuanlan.zhihu.com/p/486180243</a></p></blockquote>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0/">学习杂记</category>
      
      
      <category domain="http://yunsaijc.top/tags/Web/">Web</category>
      
      
      <comments>http://yunsaijc.top/2023/09/27/7-%E5%85%B3%E4%BA%8EHTTP%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E7%90%86%E8%A7%A3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HTB-sau Walkthrough</title>
      <link>http://yunsaijc.top/2023/09/17/6-HTB-sau-Walkthrough/</link>
      <guid>http://yunsaijc.top/2023/09/17/6-HTB-sau-Walkthrough/</guid>
      <pubDate>Sun, 17 Sep 2023 02:10:19 GMT</pubDate>
      
        
        
      <description>&lt;blockquote&gt;
&lt;p&gt;运行环境：macOS 13.2.1; Parallel Desktop: Kali Linux 2022.2 ARM64;
Windows 11&lt;/p&gt;
&lt;p&gt;靶机链接：&lt;a
href=&quot;https://app.hackthebox.com/mac</description>
        
      
      
      
      <content:encoded><![CDATA[<blockquote><p>运行环境：macOS 13.2.1; Parallel Desktop: Kali Linux 2022.2 ARM64;Windows 11</p><p>靶机链接：<ahref="https://app.hackthebox.com/machines/Sau">https://app.hackthebox.com/machines/Sau</a></p></blockquote><h2 id="过程">过程</h2><h3 id="信息收集">信息收集</h3><p>基础的四项扫描： <img src="/2023/09/17/6-HTB-sau-Walkthrough/1.png" class=""></p><p>在端口扫描时，采用默认的<code>-sS</code>方式，能够扫到<code>-sT</code>方式扫不到的80和8338端口：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/2.png" class=""><img src="/2023/09/17/6-HTB-sau-Walkthrough/3.png" class=""><img src="/2023/09/17/6-HTB-sau-Walkthrough/4.png" class=""><img src="/2023/09/17/6-HTB-sau-Walkthrough/5.png" class=""><p>扫描完成后， 进行子目录爆破：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/6.png" class=""><h3 id="web部分">Web部分</h3><p>进入<code>hostname/web/</code>，发现是一个<code>request basket</code>的Web应用，可以收集各种请求：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/7.png" class=""><p>创建一个名为<code>sau</code>的basket：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/8.png" class=""><p>搜索发现该应用存在一个SSRF漏洞<code>CVE-2023-27163</code>：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/9.png" class=""><p>尝试使用网上的脚本进行利用，但没有成功：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/10.png" class=""><p>不再尝试网上的poc，继续往下进行。</p><p>搜索发现这是一个类似于代理的应用。在设置中可以设置目标的URL。</p><p>将访问<code>http://hostname/sau</code>的主机记为主机A（攻击机），主机A想要访问的主机记为主机B。</p><p><code>Forward URL</code>是需要转发到的地址，即主机B地址；</p><p><code>Proxy Response</code>勾选后，主机B的响应会发送回主机A；</p><p><code>Expand Forward</code>勾选后，主机A访问时扩展的部分会被添到<code>Forward URL</code>的后面。如：主机A访问<code>http://hostname/sau/login</code>，如果勾选该项，那么实际访问的就是<code>&#123;Forward URL&#125;/login</code>；否则就是<code>&#123;Forward URL&#125;</code>，后面的<code>/login</code>是无效的。</p><p>此处务必要注意勾选后面两个！否则后续的步骤不成立！</p><p>在端口扫描过程中发现了一个80端口，但不对外开放。此处将目标URL设为服务器本地地址的80端口进行尝试：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/11.png" class=""><h3 id="主机立足">主机立足</h3><p>设置完成后访问<code>http://hostname/sau</code>，是一个名为<code>Maltrail</code>的恶意流量监测应用。搜索其漏洞：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/12.png" class=""><p>下载poc镜像到本地，利用成功。获得shell：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/13.png" class=""><p>获得userflag：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/14.png" class=""><h3 id="提权">提权</h3><p>通过<code>sudo -l</code>查看权限后，在GTFOBins查找提权方法并进行提权：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/15.png" class=""><p>获得systemflag：</p><img src="/2023/09/17/6-HTB-sau-Walkthrough/16.png" class=""><h2 id="总结">总结</h2><ol type="1"><li>Request-basket存在SSRF，可以访问服务器本地的80端口</li><li>Maltrail自身存在漏洞</li></ol>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E9%9D%B6%E6%9C%BAWalkthrough/">靶机Walkthrough</category>
      
      
      <category domain="http://yunsaijc.top/tags/HTB/">HTB</category>
      
      <category domain="http://yunsaijc.top/tags/RedTeam/">RedTeam</category>
      
      
      <comments>http://yunsaijc.top/2023/09/17/6-HTB-sau-Walkthrough/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HTB-cozyhosting Walkthrough</title>
      <link>http://yunsaijc.top/2023/09/10/5-HTB-cozyhosting-Walkthrough/</link>
      <guid>http://yunsaijc.top/2023/09/10/5-HTB-cozyhosting-Walkthrough/</guid>
      <pubDate>Sun, 10 Sep 2023 01:58:56 GMT</pubDate>
      
        
        
      <description>&lt;blockquote&gt;
&lt;p&gt;运行环境：macOS 13.2.1; Parallel Desktop: Kali Linux 2022.2 ARM64;
Windows 11&lt;/p&gt;
&lt;p&gt;靶机链接：Seasonal靶机&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;过程</description>
        
      
      
      
      <content:encoded><![CDATA[<blockquote><p>运行环境：macOS 13.2.1; Parallel Desktop: Kali Linux 2022.2 ARM64;Windows 11</p><p>靶机链接：Seasonal靶机</p></blockquote><h2 id="过程">过程</h2><h3 id="信息收集">信息收集</h3><p>在<code>/etc/hosts</code>中添加域名DNS后，使用<code>dirsearch</code>进行子目录爆破：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/1.png" class=""><h3 id="web部分">Web部分</h3><p>访问<code>/actuator</code>，这是<code>spring</code>框架下的一个组件：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/2.png" class="" title="截屏2023-09-04 22.24.05"><p>查看<code>/actuator/sessions</code>可以获得该站点的<code>SESSIONID</code>，其中<code>jq</code>命令用于处理JSON数据：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/3.png" class="" title="截屏2023-09-05 10.17.15"><p>在登录页面输入，提交后抓包修改<code>SESSIONID</code>。此后每一个数据包均对<code>SESSIONID</code>进行修改，即可登录admin页面</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/4.png" class="" title="截屏2023-09-05 10.18.02"><p>登录admin页面后发现存在两处输入框。其中<code>username</code>参数存在RCE，尝试反弹shell：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/5.png" class="" title="截屏2023-09-05 11.06.24"><p>上述方式没有成功，尝试使用curl方式反弹shell。在kali的<code>/var/www/html</code>目录下创建脚本文件，并打开apache服务：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/6.png" class="" title="截屏2023-09-05 11.14.47"><p>使用curl命令反弹shell，可以发现已经成功获得shell：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/7.png" class="" title="截屏2023-09-05 11.15.07"><h3 id="主机立足">主机立足</h3><p>查看当前目录，发现存在一个jar文件。尝试scp方式，但服务器未开启ssh服务。转而使用python开启服务：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/8.png" class="" title="截屏2023-09-06 09.09.31"><p>从而在kali上可以下载到该文件：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/9.png" class="" title="截屏2023-09-06 09.09.37"><p>审阅该文件发现存在数据库的登录信息：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/10.png" class="" title="截屏2023-09-06 09.25.10"><p>还可以使用如下命令，无需打开jar包，直接对敏感信息进行查找：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/11.png" class="" title="截屏2023-09-06 09.32.13"><p>使用该登录信息登录数据库，查看现有数据库并切换到<code>cozyhosting</code>数据库：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/12.png" class="" title="截屏2023-09-06 10.19.45"><p>查看现有表，并查看<code>users</code>表中的内容，获得两个登录密码的哈希值：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/13.png" class="" title="截屏2023-09-06 10.22.05"><p>使用<code>john</code>破解得到某一用户的登录密码：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/14.png" class="" title="截屏2023-09-06 11.53.02"><p>查看<code>/home</code>目录，以查看登录所需的用户名：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/15.png" class="" title="截屏2023-09-06 11.53.57"><p>使用<code>josh</code>用户和破解得到的密码进行ssh登录：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/16.png" class="" title="截屏2023-09-06 11.54.40"><p>得到userflag：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/17.png" class="" title="截屏2023-09-06 11.57.22"><h3 id="提权">提权</h3><p>查看当前用户权限，可以免密以root身份运行ssh：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/18.png" class="" title="截屏2023-09-06 11.59.35"><p>在GTFOBins查找提权命令：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/19.png" class="" title="截屏2023-09-06 12.01.23"><p>提权成功，获得systemflag：</p><img src="/2023/09/10/5-HTB-cozyhosting-Walkthrough/20.png" class="" title="截屏2023-09-06 12.06.06"><h2 id="总结">总结</h2><ol type="1"><li>spring框架下的actuator组件，存在敏感信息泄漏漏洞。从而导致session会话劫持攻击</li><li>admin页面存在RCE漏洞</li><li>jar包存在敏感信息泄漏漏洞</li></ol>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E9%9D%B6%E6%9C%BAWalkthrough/">靶机Walkthrough</category>
      
      
      <category domain="http://yunsaijc.top/tags/HTB/">HTB</category>
      
      <category domain="http://yunsaijc.top/tags/RedTeam/">RedTeam</category>
      
      
      <comments>http://yunsaijc.top/2023/09/10/5-HTB-cozyhosting-Walkthrough/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HTB-keeper Walkthrough</title>
      <link>http://yunsaijc.top/2023/09/07/4-HTB-keeper-Walkthrough/</link>
      <guid>http://yunsaijc.top/2023/09/07/4-HTB-keeper-Walkthrough/</guid>
      <pubDate>Thu, 07 Sep 2023 02:03:54 GMT</pubDate>
      
        
        
      <description>&lt;blockquote&gt;
&lt;p&gt;运行环境：macOS 13.2.1; Parallel Desktop: Kali Linux 2022.2 ARM64;
Windows 11&lt;/p&gt;
&lt;p&gt;靶机链接：&lt;a
href=&quot;https://app.hackthebox.com/mac</description>
        
      
      
      
      <content:encoded><![CDATA[<blockquote><p>运行环境：macOS 13.2.1; Parallel Desktop: Kali Linux 2022.2 ARM64;Windows 11</p><p>靶机链接：<ahref="https://app.hackthebox.com/machines/Keeper">https://app.hackthebox.com/machines/Keeper</a></p></blockquote><h2 id="过程">过程</h2><h3 id="信息收集">信息收集</h3><p>首先进行4项基本扫描：端口扫描，详细信息扫描，UDP扫描，漏洞扫描</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/1.png" class=""><p>发现22和80端口开放：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/2.png" class=""><img src="/2023/09/07/4-HTB-keeper-Walkthrough/3.png" class=""><img src="/2023/09/07/4-HTB-keeper-Walkthrough/4.png" class=""><h3 id="web部分">Web部分</h3><p>访问Web页面：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/5.png" class=""><p>在<code>/etc/hosts</code>中添加ip和域名：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/6.png" class=""><p>访问前面提到的域名，是一个登录页面。查看该开源项目(RT)的源码可以得到默认的用户名和密码<code>root:password</code>，尝试登录：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/7.png" class=""><p>成功登录之后，找到某个用户的用户名和密码信息：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/8.png" class=""><h3 id="主机立足">主机立足</h3><p>使用上述信息尝试ssh登录，成功。获得userflag：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/9.png" class=""><h3 id="提权">提权</h3><p>解压<code>RT30000.zip</code>后发现是有关Keepass的两个文件。通过搜索引擎找到该软件的漏洞<code>CVE-2023-32784</code>：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/10.png" class=""><p>找到该漏洞的poc：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/11.png" class=""><p>通过scp将该poc上传到服务器并执行，获得可能的Keepass主密码，但难以辨认其中的字符：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/12.png" class=""><p>OCR之后搜索一下首个字符串，发现是某道菜名：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/13.png" class=""><p>将服务器上的<code>kdbx</code>文件下载到本地：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/14.png" class=""><p>打开<code>kdbx</code>文件，将该菜名作为主密码登录（注意首字母改成小写）：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/15.png" class=""><p>获得一个密码和一个<code>putty</code>文件的内容。将该密码作为<code>root</code>用户的密码ssh登录失败，可能是因为没有开启密码登录：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/16.png" class=""><p>将<code>putty</code>文件的内容保存为<code>ppk</code>文件：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/17.png" class=""><p>通过命令<code>putty -i ./putty.ppk</code>指定该文件，并打开putty，登录服务器：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/18.png" class=""><p>可以看到能够直接以<code>root</code>用户身份登录，获得systemflag：</p><img src="/2023/09/07/4-HTB-keeper-Walkthrough/19.png" class=""><h2 id="总结">总结</h2><ol type="1"><li>应用RT框架时存在弱密码漏洞（使用默认密码）</li><li>Keepass自身存在漏洞</li></ol>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E9%9D%B6%E6%9C%BAWalkthrough/">靶机Walkthrough</category>
      
      
      <category domain="http://yunsaijc.top/tags/HTB/">HTB</category>
      
      <category domain="http://yunsaijc.top/tags/RedTeam/">RedTeam</category>
      
      
      <comments>http://yunsaijc.top/2023/09/07/4-HTB-keeper-Walkthrough/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>联邦学习+差分隐私项目记录</title>
      <link>http://yunsaijc.top/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/</link>
      <guid>http://yunsaijc.top/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/</guid>
      <pubDate>Sun, 08 Jan 2023 05:44:45 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;本项目为联邦学习+差分隐私的实现(暂且记为myFed)。支持同步、异步、半异步（默认）机制。&lt;/p&gt;
&lt;p&gt;项目仓库：&lt;a
href=&quot;https://github.com/yunsaijc/2023-Federated-Learning-and-Differential-</description>
        
      
      
      
      <content:encoded><![CDATA[<p>本项目为联邦学习+差分隐私的实现(暂且记为myFed)。支持同步、异步、半异步（默认）机制。</p><p>项目仓库：<ahref="https://github.com/yunsaijc/2023-Federated-Learning-and-Differential-Privacy">https://github.com/yunsaijc/2023-Federated-Learning-and-Differential-Privacy</a></p><p>本代码基于以下仓库实现：<ahref="https://github.com/wenzhu23333/Differential-Privacy-Based-Federated-Learning">https://github.com/wenzhu23333/Differential-Privacy-Based-Federated-Learning</a></p><p>主要参考文献：</p><blockquote><p>FedSA: A Semi-Asynchronous Federated Learning Mechanism inHeterogeneous Edge Computing</p><p>Federated Learning With Differential Privacy: Algorithms andPerformance Analysis</p></blockquote><h2 id="重要参数定义与说明">重要参数定义与说明</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">M//每一轮参与全局训练的客户数量</span><br><span class="line">N//客户数量</span><br><span class="line">K//全局更新的轮数</span><br><span class="line">tau//陈旧度</span><br><span class="line">epsilon//隐私预算</span><br></pre></td></tr></table></figure><h2 id="项目目的">项目目的</h2><p>本项目主要目的是学习理解联邦学习的工作过程。探究联邦学习加上差分隐私后的效果；同时考察在半异步机制下，不同M值对于准确率和收敛时间带来的影响。</p><h2 id="项目结构">项目结构</h2><p>项目文件结构及说明如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">myFed</span><br><span class="line">│  myFed.py//项目main文件</span><br><span class="line">│  requirements.txt//依赖包与版本</span><br><span class="line">│</span><br><span class="line">├─data//存放数据集文件</span><br><span class="line">├─log//代码运行记录</span><br><span class="line">├─models//网络模型相关文件</span><br><span class="line">│  │  Fed.py        //全局更新函数</span><br><span class="line">│  │  Nets.py       //网络模型定义函数</span><br><span class="line">│  │  test.py       //测试准确率函数</span><br><span class="line">│  │  Update.py     //本地更新函数</span><br><span class="line">│</span><br><span class="line">├─utils//存放一些使用到的函数</span><br><span class="line">│  │  dataset.py            //数据集有关函数</span><br><span class="line">│  │  dp_mechanism.py       //与dp有关的函数</span><br><span class="line">│  │  Functions.py          //其他函数</span><br><span class="line">│  │  language_utils.py     //与特定语言模型有关的函数</span><br><span class="line">│  │  options.py            //命令行参数设置函数</span><br><span class="line">│  │  sampling.py           //数据集划分函数</span><br></pre></td></tr></table></figure><h2 id="实验设置">实验设置</h2><p>本项目中，我进行了多次实验。各个实验设置如下：（数据分布：IID/Non-IID；数据集：MNIST/CIFAR-10）</p><ol type="1"><li>半异步机制联邦学习+差分隐私，设置不同N值。</li><li>半异步机制联邦学习+差分隐私，设置不同M值。</li><li>五种机制对比：myFed, FedSA, FedAsync, FedAP, FedAF；</li></ol><h2 id="实验结果分析">实验结果分析</h2><h3 id="设置不同n值">1. 设置不同N值</h3><p>在不同的N值之下，各个客户端陈旧度的最大值随着N值的增大而增加。如下图所示：</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/tau_iid_CNN_MNIST-16731516267212.png" class=""><h3 id="设置不同m值">2. 设置不同M值</h3><p>令N的值固定，变量为M的值。在IID数据集下的实验结果如下图所示（图例中的值为<spanclass="math inline">\(\frac{M}{N}\)</span>）。可以发现，当M的值较小时，收敛速度更快，并且准确率也有略微的领先。</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/4_acc_iid_CNN_MNIST.png" class=""><p>在Non-IID数据集下的实验结果如下图所示。可以发现，当数据分布为Non-IID时，仍然是M的值较小时，准确率上升地更快；但是M较小时的准确率波动程度较大，甚至会无法收敛；而M的值较大时虽然准确率上升更慢，但准确率是较为稳定，并且能够收敛的。</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/4_acc_N-iid_CNN_MNIST.png" class=""><h3 id="五种机制对比">3. 五种机制对比</h3><p>本实验将myFed(半异步), FedSA(半异步), FedAsync(异步), FedAP(同步),FedAF(同步)五种机制的性能进行了对比。</p><p>MNIST数据集，IID分布下。</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/acc_iid_CNN_MNIST.png" class=""><p>MNIST数据集，Non-IID分布下。</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/acc_N-iid_CNN_MNIST.png" class=""><p>CIFAR-10数据集，IID分布下。</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/acc_iid_CNN_CIFAR.png" class=""><p>CIFAR-10数据集，Non-IID分布下。</p><img src="/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/acc_N-iid_CNN_CIFAR.png" class=""><h2 id="参考">参考</h2><blockquote><p>Q. Ma, Y. Xu, H. Xu, Z. Jiang, L. Huang and H. Huang, "FedSA: ASemi-Asynchronous Federated Learning Mechanism in Heterogeneous EdgeComputing," in IEEE Journal on Selected Areas in Communications, vol.39, no. 12, pp. 3654-3672, Dec. 2021, doi:10.1109/JSAC.2021.3118435.</p><p>K. Wei et al., "Federated Learning With Differential Privacy:Algorithms and Performance Analysis," in IEEE Transactions onInformation Forensics and Security, vol. 15, pp. 3454-3469, 2020, doi:10.1109/TIFS.2020.2988575.</p><p><ahref="https://blog.csdn.net/qq_36018871/article/details/121361027">https://blog.csdn.net/qq_36018871/article/details/121361027</a></p><p><ahref="https://zhuanlan.zhihu.com/p/263959892?utm_source=wechat_session">https://zhuanlan.zhihu.com/p/263959892?utm_source=wechat_session</a></p><p><ahref="https://blog.csdn.net/m0_54487794/article/details/121674633">https://blog.csdn.net/m0_54487794/article/details/121674633</a></p><p><ahref="https://blog.csdn.net/wenzhu2333/article/details/124556920?spm=1001.2014.3001.5501">https://blog.csdn.net/wenzhu2333/article/details/124556920?spm=1001.2014.3001.5501</a></p><p><ahref="https://zhuanlan.zhihu.com/p/348290670">https://zhuanlan.zhihu.com/p/348290670</a></p><p><ahref="https://blog.csdn.net/Lyn_S/article/details/119661088">https://blog.csdn.net/Lyn_S/article/details/119661088</a></p><p><ahref="https://www.zhihu.com/question/354819140">https://www.zhihu.com/question/354819140</a></p><p><ahref="https://zhuanlan.zhihu.com/p/142597513">https://zhuanlan.zhihu.com/p/142597513</a></p><p><ahref="https://blog.csdn.net/qq_41769289/article/details/87694955">https://blog.csdn.net/qq_41769289/article/details/87694955</a></p><p><ahref="https://blog.fangzhou.me/posts/20190224-gradient-descent/#l-smooth-and-%CE%BC-strongly-convex-function">https://blog.fangzhou.me/posts/20190224-gradient-descent/#l-smooth-and-%CE%BC-strongly-convex-function</a></p><p><ahref="https://blog.fangzhou.me/posts/20190217-convex-function-lipschitz-smooth-strongly-convex/#strongly-convex">https://blog.fangzhou.me/posts/20190217-convex-function-lipschitz-smooth-strongly-convex/#strongly-convex</a></p><p><ahref="https://blog.csdn.net/qsczse943062710/article/details/76423509">https://blog.csdn.net/qsczse943062710/article/details/76423509</a></p><p><ahref="https://blog.csdn.net/qq_42589613/article/details/110296048">https://blog.csdn.net/qq_42589613/article/details/110296048</a></p><p><ahref="https://blog.csdn.net/PanYHHH/article/details/107361827">https://blog.csdn.net/PanYHHH/article/details/107361827</a></p><p><ahref="https://zhuanlan.zhihu.com/p/40761721">https://zhuanlan.zhihu.com/p/40761721</a></p></blockquote>]]></content:encoded>
      
      
      <category domain="http://yunsaijc.top/categories/%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/">项目记录</category>
      
      
      <category domain="http://yunsaijc.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</category>
      
      <category domain="http://yunsaijc.top/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">联邦学习</category>
      
      <category domain="http://yunsaijc.top/tags/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/">差分隐私</category>
      
      <category domain="http://yunsaijc.top/tags/CNN/">CNN</category>
      
      
      <comments>http://yunsaijc.top/2023/01/08/3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0+%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
